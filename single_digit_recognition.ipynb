{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b7ef0f7-2849-44d2-9eac-61ced5a8eb7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[0:01:25.430375740] [1805] \u001b[1;32m INFO \u001b[1;37mCamera \u001b[1;34mcamera_manager.cpp:330 \u001b[0mlibcamera v0.5.2+99-bfd68f78\n",
      "[0:01:25.476702297] [1839] \u001b[1;32m INFO \u001b[1;37mIPAProxy \u001b[1;34mipa_proxy.cpp:180 \u001b[0mUsing tuning file /usr/share/libcamera/ipa/rpi/vc4/ov5647.json\n",
      "[0:01:25.482627508] [1839] \u001b[1;32m INFO \u001b[1;37mCamera \u001b[1;34mcamera_manager.cpp:220 \u001b[0mAdding camera '/base/soc/i2c0mux/i2c@1/ov5647@36' for pipeline handler rpi/vc4\n",
      "[0:01:25.482667118] [1839] \u001b[1;32m INFO \u001b[1;37mRPI \u001b[1;34mvc4.cpp:440 \u001b[0mRegistered camera /base/soc/i2c0mux/i2c@1/ov5647@36 to Unicam device /dev/media0 and ISP device /dev/media1\n",
      "[0:01:25.482702802] [1839] \u001b[1;32m INFO \u001b[1;37mRPI \u001b[1;34mpipeline_base.cpp:1107 \u001b[0mUsing configuration file '/usr/share/libcamera/pipeline/rpi/vc4/rpi_apps.yaml'\n",
      "[0:01:25.491750743] [1805] \u001b[1;32m INFO \u001b[1;37mCamera \u001b[1;34mcamera.cpp:1215 \u001b[0mconfiguring streams: (0) 640x480-XRGB8888/SMPTE170M/Rec709/None/Full (1) 640x480-SGBRG10_CSI2P/RAW\n",
      "[0:01:25.492181747] [1839] \u001b[1;32m INFO \u001b[1;37mRPI \u001b[1;34mvc4.cpp:615 \u001b[0mSensor: /base/soc/i2c0mux/i2c@1/ov5647@36 - Selected sensor format: 640x480-SGBRG10_1X10/RAW - Selected unicam format: 640x480-pGAA/RAW\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4853e34a93564e37921ff4698b85be6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image(value=b'', format='jpeg')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Project based on the RaspRover image UGV_S10_240518.zip -> https://drive.google.com/file/d/1ELeIAsUIQ6ydEsc19Vssc6X0nz1myuJ_/view\n",
    "# Modified and extended by Johny Roa Müller, 2025\n",
    "\n",
    "# digit recognition\n",
    "\n",
    "from picamera2 import Picamera2\n",
    "import cv2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import ipywidgets as widgets\n",
    "from logger_configurator import setup_ugv_logger\n",
    "from time import sleep\n",
    "\n",
    "logger = setup_ugv_logger()\n",
    "\n",
    "# MNIST-Modell\n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(28*28, 128)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc3 = nn.Linear(64, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "# Modell laden\n",
    "model = SimpleNN()\n",
    "model.load_state_dict(torch.load('mnist_model.pth'))\n",
    "model.to(\"cpu\")\n",
    "model.eval()\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "])\n",
    "\n",
    "# Picamera2 initialisieren\n",
    "picam2 = Picamera2()\n",
    "picam2.configure(picam2.create_video_configuration(main={\"format\": 'XRGB8888', \"size\": (640, 480)}))\n",
    "picam2.start()\n",
    "\n",
    "camera_display_handle = widgets.Image(format='jpeg')\n",
    "display(camera_display_handle)\n",
    "\n",
    "\n",
    "lower_blue = np.array([110, 50, 50])   # H 110–130, S ≥50, V ≥50\n",
    "upper_blue = np.array([130, 255, 255]) # V bis 255\n",
    "\n",
    "lower_green = np.array([60, 50, 50])    # H 60–90, S ≥50, V ≥50\n",
    "upper_green = np.array([90, 255, 255])  # maximale Sättigung & Helligkeit\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "try:\n",
    "    while True:\n",
    "        frame = picam2.capture_array()\n",
    "        hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "        \n",
    "        # Maske für die blaue Ziffer\n",
    "        mask = cv2.inRange(hsv, lower_blue, upper_blue) # green\n",
    "        \n",
    "        # Morphologie: kleine Löcher schließen und Ziffer dicker machen\n",
    "        kernel = np.ones((3,3), np.uint8)\n",
    "        mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel)\n",
    "        mask = cv2.dilate(mask, kernel, iterations=1)\n",
    "        mask = cv2.medianBlur(mask, 3)\n",
    "        \n",
    "        # Invertieren für MNIST (weiße Ziffer auf schwarzem Hintergrund)\n",
    "        #bw = cv2.bitwise_not(mask)\n",
    "\n",
    "        # Resize für PyTorch\n",
    "        resized = cv2.resize(mask, (28,28), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "        # Anzeige in groß\n",
    "        display_img = cv2.resize(mask, (280,280), interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "        # Tensor\n",
    "        tensor = transform(resized).unsqueeze(0)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(tensor)\n",
    "            probs = torch.nn.functional.softmax(outputs, dim=1)\n",
    "            confidence, pred = torch.max(probs, 1)\n",
    "            if confidence.item() > 0.95:\n",
    "                logger.info(f\"Predicted digit: {pred.item()} (confidence: {confidence.item():.2f})\")\n",
    "            else:\n",
    "                logger.info(\"No confident prediction.\")\n",
    "\n",
    "        _, frame_jpeg = cv2.imencode('.jpeg', display_img)\n",
    "        camera_display_handle.value = frame_jpeg.tobytes()\n",
    "\n",
    "\n",
    "finally:\n",
    "    cv2.destroyAllWindows()\n",
    "    picam2.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8174f797-7523-4a7c-9f6c-9678f116f035",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
