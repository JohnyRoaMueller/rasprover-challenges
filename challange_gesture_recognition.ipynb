{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa558352-4610-4a4c-9466-b0d1aad9caf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "798bb273f37848119a66cab180094cb5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ToggleButton(value=False, button_style='danger', description='Stop', icon='square', tooltip='Description')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[0:26:18.128935873] [4565] \u001b[1;32m INFO \u001b[1;37mCamera \u001b[1;34mcamera_manager.cpp:330 \u001b[0mlibcamera v0.5.2+99-bfd68f78\n",
      "[0:26:18.178142292] [4566] \u001b[1;32m INFO \u001b[1;37mIPAProxy \u001b[1;34mipa_proxy.cpp:180 \u001b[0mUsing tuning file /usr/share/libcamera/ipa/rpi/vc4/ov5647.json\n",
      "[0:26:18.187121408] [4566] \u001b[1;32m INFO \u001b[1;37mCamera \u001b[1;34mcamera_manager.cpp:220 \u001b[0mAdding camera '/base/soc/i2c0mux/i2c@1/ov5647@36' for pipeline handler rpi/vc4\n",
      "[0:26:18.187244388] [4566] \u001b[1;32m INFO \u001b[1;37mRPI \u001b[1;34mvc4.cpp:440 \u001b[0mRegistered camera /base/soc/i2c0mux/i2c@1/ov5647@36 to Unicam device /dev/media3 and ISP device /dev/media0\n",
      "[0:26:18.187349831] [4566] \u001b[1;32m INFO \u001b[1;37mRPI \u001b[1;34mpipeline_base.cpp:1107 \u001b[0mUsing configuration file '/usr/share/libcamera/pipeline/rpi/vc4/rpi_apps.yaml'\n",
      "[0:26:18.199153006] [4565] \u001b[1;32m INFO \u001b[1;37mCamera \u001b[1;34mcamera.cpp:1215 \u001b[0mconfiguring streams: (0) 640x480-XRGB8888/SMPTE170M/Rec709/None/Full (1) 640x480-SGBRG10_CSI2P/RAW\n",
      "[0:26:18.199574686] [4566] \u001b[1;32m INFO \u001b[1;37mRPI \u001b[1;34mvc4.cpp:615 \u001b[0mSensor: /base/soc/i2c0mux/i2c@1/ov5647@36 - Selected sensor format: 640x480-SGBRG10_1X10/RAW - Selected unicam format: 640x480-pGAA/RAW\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import cv2  # Import the OpenCV library for image processing\n",
    "import imutils, math  # Auxiliary libraries for image processing and mathematical operations\n",
    "from picamera2 import Picamera2  # Library for accessing the Raspberry Pi Camera\n",
    "from IPython.display import display, Image  # Library for displaying images in Jupyter Notebook\n",
    "import ipywidgets as widgets  # Library for creating interactive widgets such as buttons\n",
    "import threading  # Library for creating new threads to execute tasks asynchronously\n",
    "import mediapipe as mp  # Import the MediaPipe library for hand keypoint detection\n",
    "from time import sleep\n",
    "from logger_configurator import setup_ugv_logger\n",
    "\n",
    "logger = setup_ugv_logger()\n",
    "\n",
    "###################################################\n",
    "###################TTS#############################\n",
    "###################################################\n",
    "import pyttsx3  # Importing the pyttsx3 library for text-to-speech functionality\n",
    "import threading  # Importing the threading module for creating threads\n",
    "\n",
    "# Initializing the pyttsx3 engine\n",
    "engine = pyttsx3.init()\n",
    "\n",
    "# Creating an event object to control the synchronization of audio playback\n",
    "play_audio_event = threading.Event()\n",
    "\n",
    "# Setting the speed of voice playback\n",
    "engine.setProperty('rate', 180)\n",
    "\n",
    "# Defining a function to play voice for the given text\n",
    "def play_speech(input_text):\n",
    "    engine.say(input_text)  # Inputting the text into the engine\n",
    "    engine.runAndWait()  # Waiting for the voice output to complete\n",
    "    play_audio_event.clear()  # Clearing the event to indicate voice playback is complete\n",
    "\n",
    "def play_speech_thread(input_text):\n",
    "    if play_audio_event.is_set():  # If a voice is already being played, return immediately to avoid overlapping playback\n",
    "        return\n",
    "    play_audio_event.set()  # Setting the event to indicate a new voice playback task has started\n",
    "    # Creating a new thread to play voice using the play_speech function\n",
    "    speech_thread = threading.Thread(target=play_speech, args=(input_text,))\n",
    "    speech_thread.start()  # Starting the new thread to begin voice playback\n",
    "\n",
    "###################################################\n",
    "###################TTS#############################\n",
    "###################################################\n",
    "\n",
    "# Create a \"Stop\" button that allows the user to stop the video stream by clicking on it\n",
    "# ================\n",
    "stopButton = widgets.ToggleButton(\n",
    "    value=False,\n",
    "    description='Stop',\n",
    "    disabled=False,\n",
    "    button_style='danger',  # Button style: 'success', 'info', 'warning', 'danger', or ''\n",
    "    tooltip='Description',\n",
    "    icon='square'  # FontAwesome icon name (without the `fa-` prefix)\n",
    ")\n",
    "\n",
    "# Initialize MediaPipe drawing utilities and hand keypoint detection model\n",
    "mpDraw = mp.solutions.drawing_utils\n",
    "mpHands = mp.solutions.hands\n",
    "hands = mpHands.Hands(max_num_hands=1)  # Initialize the hand keypoint detection model to detect up to one hand\n",
    "\n",
    "\n",
    "def detect_mano_cornuta(fp):\n",
    "    if fp[\"wrist_y\"] > fp[\"index_tip_y\"] and fp[\"wrist_y\"] > fp[\"pinky_tip_y\"]: # handfläche unterhalb der finger\n",
    "        if fp[\"index_tip_y\"] < fp[\"index_dip_y\"] < fp[\"index_pip_y\"] < fp[\"index_mcp_y\"]: # zeigefinger gestreckt\n",
    "            if fp[\"pinky_tip_y\"] < fp[\"pinky_dip_y\"] < fp[\"pinky_pip_y\"] < fp[\"pinky_mcp_y\"]: # kleiner finger gestreckt\n",
    "                if fp[\"middle_tip_y\"] > fp[\"index_mcp_y\"] and fp[\"ring_tip_y\"] > fp[\"ring_mcp_y\"]: # Mittel- Ringerfingerspitze unterhalb von Handballen\n",
    "                    logger.info(\"mano cornuta\")\n",
    "                    play_speech(\"mano cornuta\")\n",
    "                    sleep(1)\n",
    "\n",
    "def detect_mano_cornuta_neg(fp):\n",
    "    if fp[\"wrist_y\"] < fp[\"index_tip_y\"] and fp[\"wrist_y\"] < fp[\"pinky_tip_y\"]: # handfläche unterhalb der finger\n",
    "        if fp[\"index_tip_y\"] > fp[\"index_dip_y\"] > fp[\"index_pip_y\"] > fp[\"index_mcp_y\"]: # zeigefinger gestreckt\n",
    "            if fp[\"pinky_tip_y\"] > fp[\"pinky_dip_y\"] > fp[\"pinky_pip_y\"] > fp[\"pinky_mcp_y\"]: # kleiner finger gestreckt\n",
    "                if fp[\"middle_tip_y\"] < fp[\"index_mcp_y\"] and fp[\"ring_tip_y\"] < fp[\"ring_mcp_y\"]: # Mittel- Ringerfingerspitze unterhalb von Handballen\n",
    "                    logger.info(\"mano cornuta\")\n",
    "                    play_speech(\"mano cornuta\")\n",
    "                    sleep(1)\n",
    "\n",
    "\n",
    "def showPos(x, y, z):\n",
    "    logger.info(f'x: ${x} - x-x-x')\n",
    "    logger.info(\"---\")\n",
    "    logger.info(f'y: ${y} --- y-y-y')\n",
    "    logger.info(\"---\")\n",
    "    logger.info(f'z: ${z} ----- z-z-z')\n",
    "    logger.info(\"---\")\n",
    "    #detect_mano_carnuta(fp)\n",
    "    sleep(0.5)\n",
    "    \n",
    "\n",
    "# Define the display function to process video frames and perform hand keypoint detection\n",
    "def view(button):\n",
    "    # If you are using a CSI camera, uncomment the picam2 related code below, \n",
    "    # and comment out the camera related code.\n",
    "    # This is because the latest version of OpenCV (4.9.0.80) no longer supports CSI cameras, \n",
    "    # and you need to use picamera2 to capture camera images.\n",
    "    \n",
    "    picam2 = Picamera2()  # Create an instance of Picamera2\n",
    "    picam2.configure(picam2.create_video_configuration(main={\"format\": 'XRGB8888', \"size\": (640, 480)}))  # Configure camera parameters\n",
    "    picam2.start()  # Start the camera\n",
    "    \n",
    "    # camera = cv2.VideoCapture(-1) \n",
    "    # camera.set(cv2.CAP_PROP_FRAME_WIDTH, 640)\n",
    "    # camera.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)\n",
    "    \n",
    "    display_handle=display(None, display_id=True)  # Create a display handle to update the displayed image\n",
    "    \n",
    "    while True:\n",
    "        frame = picam2.capture_array()\n",
    "        # _, frame = camera.read()\n",
    "        # frame = cv2.flip(frame, 1) # If your camera reverses your image\n",
    "\n",
    "        img = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)\n",
    "        results = hands.process(img)\n",
    "\n",
    "        # If hand keypoints are detected\n",
    "        if results.multi_hand_landmarks:\n",
    "            for handLms in results.multi_hand_landmarks:  # Iterate through each detected hand\n",
    "                # Draw hand keypoints\n",
    "                for id, lm in enumerate(handLms.landmark):\n",
    "                    h, w, c = img.shape\n",
    "                    cx, cy = int(lm.x * w), int(lm.y * h)  # Calculate the position of the keypoint in the image\n",
    "                    cv2.circle(img, (cx, cy), 5, (255, 0, 0), -1)  # Draw a circle at the keypoint position\n",
    "\n",
    "                \n",
    "                frame = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)\n",
    "                mpDraw.draw_landmarks(frame, handLms, mpHands.HAND_CONNECTIONS)  # Draw hand skeleton connections\n",
    "                # frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB) \n",
    "\n",
    "                target_pos = handLms.landmark[mpHands.HandLandmark.INDEX_FINGER_TIP]\n",
    "\n",
    "                fp = { # finger position\n",
    "                    # Wrist\n",
    "                    \"wrist_x\": handLms.landmark[mpHands.HandLandmark.WRIST].x,\n",
    "                    \"wrist_y\": handLms.landmark[mpHands.HandLandmark.WRIST].y,\n",
    "                    \"wrist_z\": handLms.landmark[mpHands.HandLandmark.WRIST].z,\n",
    "                    \n",
    "                    # Thumb\n",
    "                    \"thumb_cmc_x\": handLms.landmark[mpHands.HandLandmark.THUMB_CMC].x,\n",
    "                    \"thumb_cmc_y\": handLms.landmark[mpHands.HandLandmark.THUMB_CMC].y,\n",
    "                    \"thumb_cmc_z\": handLms.landmark[mpHands.HandLandmark.THUMB_CMC].z,\n",
    "                \n",
    "                    \"thumb_mcp_x\": handLms.landmark[mpHands.HandLandmark.THUMB_MCP].x,\n",
    "                    \"thumb_mcp_y\": handLms.landmark[mpHands.HandLandmark.THUMB_MCP].y,\n",
    "                    \"thumb_mcp_z\": handLms.landmark[mpHands.HandLandmark.THUMB_MCP].z,\n",
    "                \n",
    "                    \"thumb_ip_x\": handLms.landmark[mpHands.HandLandmark.THUMB_IP].x,\n",
    "                    \"thumb_ip_y\": handLms.landmark[mpHands.HandLandmark.THUMB_IP].y,\n",
    "                    \"thumb_ip_z\": handLms.landmark[mpHands.HandLandmark.THUMB_IP].z,\n",
    "                \n",
    "                    \"thumb_tip_x\": handLms.landmark[mpHands.HandLandmark.THUMB_TIP].x,\n",
    "                    \"thumb_tip_y\": handLms.landmark[mpHands.HandLandmark.THUMB_TIP].y,\n",
    "                    \"thumb_tip_z\": handLms.landmark[mpHands.HandLandmark.THUMB_TIP].z,\n",
    "                \n",
    "                    # Index finger\n",
    "                    \"index_mcp_x\": handLms.landmark[mpHands.HandLandmark.INDEX_FINGER_MCP].x,\n",
    "                    \"index_mcp_y\": handLms.landmark[mpHands.HandLandmark.INDEX_FINGER_MCP].y,\n",
    "                    \"index_mcp_z\": handLms.landmark[mpHands.HandLandmark.INDEX_FINGER_MCP].z,\n",
    "                \n",
    "                    \"index_pip_x\": handLms.landmark[mpHands.HandLandmark.INDEX_FINGER_PIP].x,\n",
    "                    \"index_pip_y\": handLms.landmark[mpHands.HandLandmark.INDEX_FINGER_PIP].y,\n",
    "                    \"index_pip_z\": handLms.landmark[mpHands.HandLandmark.INDEX_FINGER_PIP].z,\n",
    "                \n",
    "                    \"index_dip_x\": handLms.landmark[mpHands.HandLandmark.INDEX_FINGER_DIP].x,\n",
    "                    \"index_dip_y\": handLms.landmark[mpHands.HandLandmark.INDEX_FINGER_DIP].y,\n",
    "                    \"index_dip_z\": handLms.landmark[mpHands.HandLandmark.INDEX_FINGER_DIP].z,\n",
    "                \n",
    "                    \"index_tip_x\": handLms.landmark[mpHands.HandLandmark.INDEX_FINGER_TIP].x,\n",
    "                    \"index_tip_y\": handLms.landmark[mpHands.HandLandmark.INDEX_FINGER_TIP].y,\n",
    "                    \"index_tip_z\": handLms.landmark[mpHands.HandLandmark.INDEX_FINGER_TIP].z,\n",
    "                \n",
    "                    # Middle finger\n",
    "                    \"middle_mcp_x\": handLms.landmark[mpHands.HandLandmark.MIDDLE_FINGER_MCP].x,\n",
    "                    \"middle_mcp_y\": handLms.landmark[mpHands.HandLandmark.MIDDLE_FINGER_MCP].y,\n",
    "                    \"middle_mcp_z\": handLms.landmark[mpHands.HandLandmark.MIDDLE_FINGER_MCP].z,\n",
    "                \n",
    "                    \"middle_pip_x\": handLms.landmark[mpHands.HandLandmark.MIDDLE_FINGER_PIP].x,\n",
    "                    \"middle_pip_y\": handLms.landmark[mpHands.HandLandmark.MIDDLE_FINGER_PIP].y,\n",
    "                    \"middle_pip_z\": handLms.landmark[mpHands.HandLandmark.MIDDLE_FINGER_PIP].z,\n",
    "                \n",
    "                    \"middle_dip_x\": handLms.landmark[mpHands.HandLandmark.MIDDLE_FINGER_DIP].x,\n",
    "                    \"middle_dip_y\": handLms.landmark[mpHands.HandLandmark.MIDDLE_FINGER_DIP].y,\n",
    "                    \"middle_dip_z\": handLms.landmark[mpHands.HandLandmark.MIDDLE_FINGER_DIP].z,\n",
    "                \n",
    "                    \"middle_tip_x\": handLms.landmark[mpHands.HandLandmark.MIDDLE_FINGER_TIP].x,\n",
    "                    \"middle_tip_y\": handLms.landmark[mpHands.HandLandmark.MIDDLE_FINGER_TIP].y,\n",
    "                    \"middle_tip_z\": handLms.landmark[mpHands.HandLandmark.MIDDLE_FINGER_TIP].z,\n",
    "                \n",
    "                    # Ring finger\n",
    "                    \"ring_mcp_x\": handLms.landmark[mpHands.HandLandmark.RING_FINGER_MCP].x,\n",
    "                    \"ring_mcp_y\": handLms.landmark[mpHands.HandLandmark.RING_FINGER_MCP].y,\n",
    "                    \"ring_mcp_z\": handLms.landmark[mpHands.HandLandmark.RING_FINGER_MCP].z,\n",
    "                \n",
    "                    \"ring_pip_x\": handLms.landmark[mpHands.HandLandmark.RING_FINGER_PIP].x,\n",
    "                    \"ring_pip_y\": handLms.landmark[mpHands.HandLandmark.RING_FINGER_PIP].y,\n",
    "                    \"ring_pip_z\": handLms.landmark[mpHands.HandLandmark.RING_FINGER_PIP].z,\n",
    "                \n",
    "                    \"ring_dip_x\": handLms.landmark[mpHands.HandLandmark.RING_FINGER_DIP].x,\n",
    "                    \"ring_dip_y\": handLms.landmark[mpHands.HandLandmark.RING_FINGER_DIP].y,\n",
    "                    \"ring_dip_z\": handLms.landmark[mpHands.HandLandmark.RING_FINGER_DIP].z,\n",
    "                \n",
    "                    \"ring_tip_x\": handLms.landmark[mpHands.HandLandmark.RING_FINGER_TIP].x,\n",
    "                    \"ring_tip_y\": handLms.landmark[mpHands.HandLandmark.RING_FINGER_TIP].y,\n",
    "                    \"ring_tip_z\": handLms.landmark[mpHands.HandLandmark.RING_FINGER_TIP].z,\n",
    "                \n",
    "                    # Pinky\n",
    "                    \"pinky_mcp_x\": handLms.landmark[mpHands.HandLandmark.PINKY_MCP].x,\n",
    "                    \"pinky_mcp_y\": handLms.landmark[mpHands.HandLandmark.PINKY_MCP].y,\n",
    "                    \"pinky_mcp_z\": handLms.landmark[mpHands.HandLandmark.PINKY_MCP].z,\n",
    "                \n",
    "                    \"pinky_pip_x\": handLms.landmark[mpHands.HandLandmark.PINKY_PIP].x,\n",
    "                    \"pinky_pip_y\": handLms.landmark[mpHands.HandLandmark.PINKY_PIP].y,\n",
    "                    \"pinky_pip_z\": handLms.landmark[mpHands.HandLandmark.PINKY_PIP].z,\n",
    "                \n",
    "                    \"pinky_dip_x\": handLms.landmark[mpHands.HandLandmark.PINKY_DIP].x,\n",
    "                    \"pinky_dip_y\": handLms.landmark[mpHands.HandLandmark.PINKY_DIP].y,\n",
    "                    \"pinky_dip_z\": handLms.landmark[mpHands.HandLandmark.PINKY_DIP].z,\n",
    "                \n",
    "                    \"pinky_tip_x\": handLms.landmark[mpHands.HandLandmark.PINKY_TIP].x,\n",
    "                    \"pinky_tip_y\": handLms.landmark[mpHands.HandLandmark.PINKY_TIP].y,\n",
    "                    \"pinky_tip_z\": handLms.landmark[mpHands.HandLandmark.PINKY_TIP].z,\n",
    "                }\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "        _, frame = cv2.imencode('.jpeg', frame)\n",
    "        display_handle.update(Image(data=frame.tobytes()))\n",
    "\n",
    "        #showPos(target_pos.x, target_pos.y, target_pos.z)\n",
    "        detect_mano_cornuta(fp)\n",
    "        detect_mano_cornuta_neg(fp)\n",
    "        \n",
    "        if stopButton.value==True:\n",
    "            picam2.close() # If yes, close the camera\n",
    "            # cv2.release() # If yes, close the camera\n",
    "            display_handle.update(None)\n",
    "\n",
    "# Display the \"Stop\" button and start a thread to execute the display function\n",
    "# ================\n",
    "display(stopButton)\n",
    "thread = threading.Thread(target=view, args=(stopButton,))\n",
    "thread.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d7ace8-d99e-43f2-8fa9-2b94134b85f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
